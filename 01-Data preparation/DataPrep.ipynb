{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     active environment : cgcnn_matai\n",
      "    active env location : /home/hassan101/anaconda3/envs/cgcnn_matai\n"
     ]
    }
   ],
   "source": [
    "#Active environment should be cgcnn_matai\n",
    "!conda info | grep 'cgcnn_matai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MAPI_KEY = os.environ['MAPI_KEY']\n",
    "aws_akid = os.environ['AWS_KID']\n",
    "aws_sak = os.environ['AWS_AK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS authentication\n",
    "res_s3 = boto3.resource('s3', aws_access_key_id=aws_akid, aws_secret_access_key= aws_sak)\n",
    "client_s3 = boto3.client('s3', aws_access_key_id=aws_akid, aws_secret_access_key= aws_sak) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all objects in bucket\n",
    "bucket_name = 'datasets-cgcnn'\n",
    "\n",
    "response = client_s3.list_objects_v2(Bucket=bucket_name)\n",
    "for obj in response['Contents']:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_s3(file_path):\n",
    "    '''\n",
    "    Use this function as:\n",
    "    pandas_df = d.read_excel(io.BytesIO(load_from_s3('path/to/test_file.xlsx').read())) #Sheet1 will be loaded by default\n",
    "    '''\n",
    "    response = client_s3.get_object(Bucket=bucket_name, Key=file_path).get(\"Body\")\n",
    "    print(\"FILE LOADED\")\n",
    "    return response\n",
    "\n",
    "def save_to_s3(df, file_path):\n",
    "    '''\n",
    "    Use this function as:\n",
    "    save_to_s3(pandas_df, 'path/to/test_file.xlsx')\n",
    "    '''    \n",
    "    with io.BytesIO() as output:\n",
    "        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:\n",
    "            df.to_excel(writer)\n",
    "        data = output.getvalue()\n",
    "    client_s3.put_object(Bucket=bucket_name, Key=file_path, Body=data)\n",
    "    print('FILE SAVED')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESSING STEP -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is the transformation wrapper for raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query PBE band gaps from materials project to prepare DS1 for M1 development\n",
    "\n",
    "df = pd.read_csv(\n",
    "    client_s3.get_object(Bucket=bucket_name, Key=\"raw/mpids_for_m1.csv\").get(\"Body\"),\n",
    "    header=None\n",
    "    )\n",
    "\n",
    "QUERY = list(df[0].values)\n",
    "print(len(QUERY))\n",
    "\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.cif import CifParser\n",
    "MAPI_KEY = MAPI_KEY\n",
    "mpr = MPRester(MAPI_KEY)\n",
    "\n",
    "prop_bg = []\n",
    "from pymatgen.ext.matproj import MPRestError\n",
    "for i in range(0,len(QUERY)):\n",
    "    try:\n",
    "        prop_bg.append(mpr.query(QUERY[i], ['material_id','pretty_formula', 'band_gap']))\n",
    "    except MPRestError:\n",
    "        print('Error:',QUERY[i])\n",
    "    else:\n",
    "       pass\n",
    "\n",
    "# This is to check if there are any empty entries\n",
    "for i in range(0,len(prop_bg)):\n",
    "    if prop_bg[i] == []:\n",
    "        print(str(i) + ' is empty')\n",
    "        #prop_bg.remove(prop_bg[i])\n",
    "        #print(str(prop_bg[i]) + ' is deleted')\n",
    "       \n",
    "# If there are some [] entries in prop_bg then running code below will give out of range error\n",
    "import pandas as pd\n",
    "df_prop_bg = pd.DataFrame(data =[])\n",
    "df_prop_bg['mpids'] = [p[0]['material_id'] for p in prop_bg]\n",
    "df_prop_bg['formula'] = [p[0]['pretty_formula'] for p in prop_bg]\n",
    "df_prop_bg['BG_MP'] = [p[0]['band_gap'] for p in prop_bg]\n",
    "\n",
    "df_prop_bg.to_excel('Datasets/processed_step1/Dataset_DS1_fromraw.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan101/anaconda3/envs/cgcnn_matai/lib/python3.11/site-packages/pymatgen/ext/matproj.py:182: UserWarning: You are using the legacy MPRester. This version of the MPRester will no longer be updated. To access the latest data with the new MPRester, obtain a new API key from https://materialsproject.org/api and consult the docs at https://docs.materialsproject.org/ for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE LOADED\n",
      "Total entries: 189\n"
     ]
    }
   ],
   "source": [
    "# Preparing preliminary DS2 dataset for M2 development using data mined from literature\n",
    "file = 'raw/from_lit_for_m2.xlsx'\n",
    "\n",
    "import pandas as pd\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.cif import CifParser\n",
    "\n",
    "\n",
    "MAPI_KEY = MAPI_KEY\n",
    "mpr = MPRester(MAPI_KEY)\n",
    "   \n",
    "df = pd.read_excel(io.BytesIO(load_from_s3(file).read())).dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "QUERY = df['MaterialsId'].values.tolist()\n",
    "\n",
    "print('Total entries:', len(QUERY))\n",
    "\n",
    "\n",
    "\n",
    "prop_bg = []\n",
    "for i in range(0,len(QUERY)):\n",
    "    #print(mpr.get_data(QUERY[i], prop = 'band_gap')) #To check\n",
    "    prop_bg.append(mpr.query(QUERY[i], ['material_id', \"pretty_formula\", \"spacegroup.number\", \"band_gap\"]))\n",
    "    \n",
    "df_prop_bg = pd.DataFrame(data =[])\n",
    "df_prop_bg['mpids'] = [p[0]['material_id'] for p in prop_bg]\n",
    "df_prop_bg['Formula'] = [p[0]['pretty_formula'] for p in prop_bg]\n",
    "df_prop_bg['SG'] = [p[0]['spacegroup.number'] for p in prop_bg]\n",
    "df_prop_bg['BG_MP'] = [p[0]['band_gap'] for p in prop_bg]\n",
    "df_prop_bg['BG_exp'], df_prop_bg['Formula_exp'] = df['BG_exp'], df['Formula']\n",
    "\n",
    "df_prop_bg.to_excel('Datasets/processed_step1/Dataset_DS2_fromrawX.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile get_mpids_from_formulas_sg.py\n",
    "##############\n",
    "# This additional script is to get mpids using formula and SG\n",
    "##############\n",
    "import os\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.cif import CifParser\n",
    "MAPI_KEY = os.environ['MAPI_KEY']\n",
    "mpr = MPRester(MAPI_KEY)\n",
    "\n",
    "formulas = [\n",
    "'CuGaSe2',\n",
    "'CuGaSe2',\n",
    "'CuInSe2',\n",
    "#'CuIn0.5Ga0.5Se2',\n",
    "'CdTe',\n",
    "'ZnTe',\n",
    "'ZnTe',\n",
    "'CdSe',\n",
    "'CsPbI3',\n",
    "'CsGeI3',\n",
    "# 'Sr15Ga22As32',\n",
    "# 'Eu15Ga22As32',\n",
    "# 'Sr15In22As32',\n",
    "# 'Eu15In22As32',\n",
    "# 'Sr3Ga6As8',\n",
    "# 'Eu3Ga6As8',\n",
    "'GaAs',\n",
    "'InAs',\n",
    "'InP',\n",
    "'AlSb',\n",
    "'GaP',\n",
    "'GaSb'\n",
    "]\n",
    "mpids = []\n",
    "for i in range (0,len(formulas)):\n",
    "    mpids.append(mpr.get_materials_ids(formulas[i]))\n",
    "    print(mpr.get_materials_ids(formulas[i]))\n",
    "    \n",
    "mpids_concat = []\n",
    "for j in mpids:\n",
    "    for i in range (0,len(j)):\n",
    "        mpids_concat.append(j[i])\n",
    "print(mpids_concat)\n",
    "\n",
    "data = []\n",
    "for i in range(0,len(mpids_concat)):\n",
    "    data.append(mpr.query(mpids_concat[i], ['material_id', \"pretty_formula\", \"spacegroup.number\", \"band_gap\"])) \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data = [])\n",
    "df['mpids'] = [p[0]['material_id'] for p in data]\n",
    "df['Formula'] = [p[0]['pretty_formula'] for p in data]\n",
    "df['SG'] = [p[0]['spacegroup.number'] for p in data]\n",
    "df['BG_MP'] = [p[0]['band_gap'] for p in data]\n",
    "\n",
    "df.to_excel('Datasets/processed_step1/mpids_from_formulas_sg.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation data, the dataset of experimental band gaps sourced from literature was queried against materials project to find mpids, space groups and PBE band gaps. There were multiple mpids-space group combinations for same formulas, so manual sorting was done to obtain single dataset `Dataset_for_validation.xlsx` from `Dataset_for_validation_manual_1.xlsx` and `Dataset_for_validation_manual_2.xlsx`. The manual matching was based on stability of the crystals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan101/anaconda3/envs/cgcnn_matai/lib/python3.11/site-packages/pymatgen/ext/matproj.py:182: UserWarning: You are using the legacy MPRester. This version of the MPRester will no longer be updated. To access the latest data with the new MPRester, obtain a new API key from https://materialsproject.org/api and consult the docs at https://docs.materialsproject.org/ for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE LOADED\n",
      "['mp-8880', 'mp-997569', 'mp-1550']\n",
      "['mp-1228806', 'mp-1018100', 'mp-2624', 'mp-15621', 'mp-1023918']\n",
      "['mp-984718', 'mp-10044']\n",
      "['mp-422']\n",
      "['mp-1008524', 'mp-11335', 'mp-1541']\n",
      "['mp-252']\n",
      "['mp-1008559', 'mp-1479']\n",
      "['mp-3772', 'mp-33397']\n",
      "['mp-672', 'mp-2469', 'mp-1181862', 'mp-1021511', 'mp-370']\n",
      "['mp-2691', 'mp-1055', 'mp-1070']\n",
      "['mp-3078']\n",
      "['mp-406', 'mp-685146', 'mp-1492', 'mp-2388', 'mp-1066480', 'mp-1226722', 'mp-12581', 'mp-1008471', 'mp-12779']\n",
      "['mp-406', 'mp-685146', 'mp-1492', 'mp-2388', 'mp-1066480', 'mp-1226722', 'mp-12581', 'mp-1008471', 'mp-12779']\n",
      "['mp-1059094', 'mp-1244899', 'mp-1245274', 'mp-15619', 'mp-2534', 'mp-1232355', 'mp-10048', 'mp-1245074', 'mp-1245314', 'mp-603640', 'mp-8883', 'mp-1244999']\n",
      "['mp-1245288', 'mp-1245188', 'mp-1007824', 'mp-830', 'mp-804', 'mp-1245130', 'mp-1244866', 'mp-1245046', 'mp-1245295', 'mp-1244984', 'mp-2853', 'mp-1245138', 'mp-1244975', 'mp-1245095', 'mp-1245286', 'mp-1245233', 'mp-1245172', 'mp-1245258', 'mp-1245069', 'mp-1244886', 'mp-1244995', 'mp-1245150', 'mp-1244896', 'mp-1245002', 'mp-1245075', 'mp-1245132', 'mp-1245244', 'mp-1245013', 'mp-1245106', 'mp-1244884', 'mp-1245030', 'mp-1244903', 'mp-1245326', 'mp-1244927', 'mp-1244998', 'mp-1245302', 'mp-1245148', 'mp-1245165', 'mp-1244934', 'mp-1245181', 'mp-1244916', 'mp-1245033']\n",
      "['mp-8882', 'mp-971632', 'mp-2490', 'mp-971648', 'mp-1018275', 'mp-971631']\n",
      "['mp-1245217', 'mp-1156', 'mp-1245088', 'mp-1224785', 'mp-1018059', 'mp-1244877', 'mp-1245146', 'mp-684664', 'mp-1244895']\n",
      "['mp-22205', 'mp-20411', 'mp-20812']\n",
      "['mp-20457', 'mp-966800', 'mp-20351']\n",
      "['mvc-5236', 'mvc-6611', 'mvc-4323', 'mp-1245203', 'mvc-9896', 'mvc-6071', 'mp-560417', 'mp-1245116', 'mp-12979', 'mp-550172', 'mvc-15363', 'mp-1245027', 'mvc-5659', 'mp-1245126', 'mvc-11686', 'mp-1245178', 'mp-697', 'mvc-5316', 'mvc-6946', 'mp-1244941', 'mp-755071', 'mvc-13245', 'mp-12978', 'mp-555487', 'mp-1244894', 'mp-1244935', 'mp-562610', 'mp-856', 'mp-1245282', 'mvc-9648']\n",
      "['mp-10627', 'mp-1087']\n",
      "['mp-15776']\n",
      "['mp-15777', 'mp-1215508']\n",
      "['mp-20832']\n",
      "['mp-2229', 'mp-997630', 'mp-1245209', 'mp-1245255', 'mp-1245109', 'mp-1093993', 'mp-2133', 'mp-1017539', 'mp-13161', 'mp-1986', 'mp-1245015']\n",
      "['mp-1245117', 'mp-555594', 'mp-554820', 'mp-555763', 'mp-1203761', 'mp-1245050', 'mp-1245213', 'mp-561258', 'mp-554999', 'mp-555543', 'mp-555583', 'mp-1245197', 'mp-557062', 'mp-556775', 'mp-1244921', 'mp-13456', 'mp-561286', 'mp-608468', 'mp-555773', 'mp-556000', 'mp-554986', 'mp-556732', 'mp-1245068', 'mp-556448', 'mp-581602', 'mp-554004', 'mp-1244922', 'mp-1245035', 'mp-9946', 'mp-10695', 'mp-1245220', 'mp-1196782', 'mp-1244974', 'mp-556280', 'mp-553916', 'mp-1245316', 'mp-554961', 'mp-556363', 'mp-556207', 'mp-1245246', 'mp-555311', 'mp-561118', 'mp-680087', 'mp-581601', 'mp-557175', 'mp-1244969', 'mp-1244986', 'mp-1245238', 'mp-581412', 'mp-555214', 'mp-554889', 'mp-557418', 'mp-556155', 'mp-1245169', 'mp-1245319', 'mp-680085', 'mp-647075', 'mp-1245122', 'mp-560725', 'mp-1245236', 'mp-556468', 'mp-1200836', 'mp-1245216', 'mp-1200568', 'mp-1244989', 'mp-1245317', 'mp-1201158', 'mp-1245296', 'mp-555664', 'mp-557151', 'mp-557026', 'mp-1245062', 'mp-556392', 'mp-581258', 'mp-1245310', 'mp-554608', 'mp-556989', 'mp-561196', 'mp-554630', 'mp-556161', 'mp-554503', 'mp-555381', 'mp-581405', 'mp-554713', 'mp-1245070', 'mp-554829', 'mp-1245201', 'mp-556485', 'mp-556576', 'mp-556152', 'mp-556950', 'mp-1245300', 'mp-1201781', 'mp-554405', 'mp-557058', 'mp-1244979', 'mp-555079', 'mp-1245194', 'mp-1202182', 'mp-555858', 'mp-1198139', 'mp-1245082', 'mp-1245199', 'mp-1244936', 'mp-554115', 'mp-555782', 'mp-581476', 'mp-1245280', 'mp-1245054', 'mp-556815', 'mp-555280', 'mp-555628', 'mp-556105', 'mp-556716', 'mp-1245034', 'mp-554681', 'mp-1245004', 'mp-18377', 'mp-556005', 'mp-581425', 'mp-557009', 'mp-1245222', 'mp-557308', 'mp-1244980', 'mp-555151', 'mp-1244890', 'mp-555410', 'mp-10281', 'mp-555779', 'mp-560588', 'mp-556395', 'mp-582680', 'mp-1245248', 'mp-556543', 'mp-1245121', 'mp-543011', 'mp-1245136', 'mp-1199343', 'mp-554253', 'mp-1202023', 'mp-557054', 'mp-1202959', 'mp-557346', 'mp-553880', 'mp-555666', 'mp-556784']\n",
      "['mp-1190', 'mp-380', 'mp-569679']\n",
      "['mp-3595', 'mp-1215453']\n",
      "['mp-4175', 'mp-1215429']\n",
      "['mp-9281', 'mp-8884', 'mp-1071319', 'mp-2176', 'mp-541441', 'mp-948', 'mp-571195']\n",
      "['mp-8880', 'mp-997569', 'mp-1550', 'mp-1228806', 'mp-1018100', 'mp-2624', 'mp-15621', 'mp-1023918', 'mp-984718', 'mp-10044', 'mp-422', 'mp-1008524', 'mp-11335', 'mp-1541', 'mp-252', 'mp-1008559', 'mp-1479', 'mp-3772', 'mp-33397', 'mp-672', 'mp-2469', 'mp-1181862', 'mp-1021511', 'mp-370', 'mp-2691', 'mp-1055', 'mp-1070', 'mp-3078', 'mp-406', 'mp-685146', 'mp-1492', 'mp-2388', 'mp-1066480', 'mp-1226722', 'mp-12581', 'mp-1008471', 'mp-12779', 'mp-406', 'mp-685146', 'mp-1492', 'mp-2388', 'mp-1066480', 'mp-1226722', 'mp-12581', 'mp-1008471', 'mp-12779', 'mp-1059094', 'mp-1244899', 'mp-1245274', 'mp-15619', 'mp-2534', 'mp-1232355', 'mp-10048', 'mp-1245074', 'mp-1245314', 'mp-603640', 'mp-8883', 'mp-1244999', 'mp-1245288', 'mp-1245188', 'mp-1007824', 'mp-830', 'mp-804', 'mp-1245130', 'mp-1244866', 'mp-1245046', 'mp-1245295', 'mp-1244984', 'mp-2853', 'mp-1245138', 'mp-1244975', 'mp-1245095', 'mp-1245286', 'mp-1245233', 'mp-1245172', 'mp-1245258', 'mp-1245069', 'mp-1244886', 'mp-1244995', 'mp-1245150', 'mp-1244896', 'mp-1245002', 'mp-1245075', 'mp-1245132', 'mp-1245244', 'mp-1245013', 'mp-1245106', 'mp-1244884', 'mp-1245030', 'mp-1244903', 'mp-1245326', 'mp-1244927', 'mp-1244998', 'mp-1245302', 'mp-1245148', 'mp-1245165', 'mp-1244934', 'mp-1245181', 'mp-1244916', 'mp-1245033', 'mp-8882', 'mp-971632', 'mp-2490', 'mp-971648', 'mp-1018275', 'mp-971631', 'mp-1245217', 'mp-1156', 'mp-1245088', 'mp-1224785', 'mp-1018059', 'mp-1244877', 'mp-1245146', 'mp-684664', 'mp-1244895', 'mp-22205', 'mp-20411', 'mp-20812', 'mp-20457', 'mp-966800', 'mp-20351', 'mvc-5236', 'mvc-6611', 'mvc-4323', 'mp-1245203', 'mvc-9896', 'mvc-6071', 'mp-560417', 'mp-1245116', 'mp-12979', 'mp-550172', 'mvc-15363', 'mp-1245027', 'mvc-5659', 'mp-1245126', 'mvc-11686', 'mp-1245178', 'mp-697', 'mvc-5316', 'mvc-6946', 'mp-1244941', 'mp-755071', 'mvc-13245', 'mp-12978', 'mp-555487', 'mp-1244894', 'mp-1244935', 'mp-562610', 'mp-856', 'mp-1245282', 'mvc-9648', 'mp-10627', 'mp-1087', 'mp-15776', 'mp-15777', 'mp-1215508', 'mp-20832', 'mp-2229', 'mp-997630', 'mp-1245209', 'mp-1245255', 'mp-1245109', 'mp-1093993', 'mp-2133', 'mp-1017539', 'mp-13161', 'mp-1986', 'mp-1245015', 'mp-1245117', 'mp-555594', 'mp-554820', 'mp-555763', 'mp-1203761', 'mp-1245050', 'mp-1245213', 'mp-561258', 'mp-554999', 'mp-555543', 'mp-555583', 'mp-1245197', 'mp-557062', 'mp-556775', 'mp-1244921', 'mp-13456', 'mp-561286', 'mp-608468', 'mp-555773', 'mp-556000', 'mp-554986', 'mp-556732', 'mp-1245068', 'mp-556448', 'mp-581602', 'mp-554004', 'mp-1244922', 'mp-1245035', 'mp-9946', 'mp-10695', 'mp-1245220', 'mp-1196782', 'mp-1244974', 'mp-556280', 'mp-553916', 'mp-1245316', 'mp-554961', 'mp-556363', 'mp-556207', 'mp-1245246', 'mp-555311', 'mp-561118', 'mp-680087', 'mp-581601', 'mp-557175', 'mp-1244969', 'mp-1244986', 'mp-1245238', 'mp-581412', 'mp-555214', 'mp-554889', 'mp-557418', 'mp-556155', 'mp-1245169', 'mp-1245319', 'mp-680085', 'mp-647075', 'mp-1245122', 'mp-560725', 'mp-1245236', 'mp-556468', 'mp-1200836', 'mp-1245216', 'mp-1200568', 'mp-1244989', 'mp-1245317', 'mp-1201158', 'mp-1245296', 'mp-555664', 'mp-557151', 'mp-557026', 'mp-1245062', 'mp-556392', 'mp-581258', 'mp-1245310', 'mp-554608', 'mp-556989', 'mp-561196', 'mp-554630', 'mp-556161', 'mp-554503', 'mp-555381', 'mp-581405', 'mp-554713', 'mp-1245070', 'mp-554829', 'mp-1245201', 'mp-556485', 'mp-556576', 'mp-556152', 'mp-556950', 'mp-1245300', 'mp-1201781', 'mp-554405', 'mp-557058', 'mp-1244979', 'mp-555079', 'mp-1245194', 'mp-1202182', 'mp-555858', 'mp-1198139', 'mp-1245082', 'mp-1245199', 'mp-1244936', 'mp-554115', 'mp-555782', 'mp-581476', 'mp-1245280', 'mp-1245054', 'mp-556815', 'mp-555280', 'mp-555628', 'mp-556105', 'mp-556716', 'mp-1245034', 'mp-554681', 'mp-1245004', 'mp-18377', 'mp-556005', 'mp-581425', 'mp-557009', 'mp-1245222', 'mp-557308', 'mp-1244980', 'mp-555151', 'mp-1244890', 'mp-555410', 'mp-10281', 'mp-555779', 'mp-560588', 'mp-556395', 'mp-582680', 'mp-1245248', 'mp-556543', 'mp-1245121', 'mp-543011', 'mp-1245136', 'mp-1199343', 'mp-554253', 'mp-1202023', 'mp-557054', 'mp-1202959', 'mp-557346', 'mp-553880', 'mp-555666', 'mp-556784', 'mp-1190', 'mp-380', 'mp-569679', 'mp-3595', 'mp-1215453', 'mp-4175', 'mp-1215429', 'mp-9281', 'mp-8884', 'mp-1071319', 'mp-2176', 'mp-541441', 'mp-948', 'mp-571195']\n"
     ]
    }
   ],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.cif import CifParser\n",
    "MAPI_KEY = MAPI_KEY\n",
    "mpr = MPRester(MAPI_KEY)\n",
    "\n",
    "file = 'raw/from_lit_for_val.xlsx'\n",
    "df_raw = pd.read_excel(io.BytesIO(load_from_s3(file).read())).dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "formulas = df_raw.Formula.values\n",
    "\n",
    "mpids = []\n",
    "for i in range (0,len(formulas)):\n",
    "    mpids.append(mpr.get_materials_ids(formulas[i]))\n",
    "    print(mpr.get_materials_ids(formulas[i]))\n",
    "    \n",
    "mpids_concat = []\n",
    "for j in mpids:\n",
    "    for i in range (0,len(j)):\n",
    "        mpids_concat.append(j[i])\n",
    "print(mpids_concat)\n",
    "\n",
    "data = []\n",
    "for i in range(0,len(mpids_concat)):\n",
    "    data.append(mpr.query(mpids_concat[i], ['material_id', \"pretty_formula\", \"spacegroup.number\", \"band_gap\"])) \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data = [])\n",
    "df['mpids'] = [p[0]['material_id'] for p in data]\n",
    "df['Formula'] = [p[0]['pretty_formula'] for p in data]\n",
    "\n",
    "df_raw.to_excel('Datasets/processed_step1/Dataset_for_validation_manual_1.xlsx')\n",
    "df.to_excel('Datasets/processed_step1/Dataset_for_validation_manual_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got additional datasets for enrichment of DS2\n",
    "\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.cif import CifParser\n",
    "MAPI_KEY = MAPI_KEY\n",
    "mpr = MPRester(MAPI_KEY)\n",
    "\n",
    "\n",
    "file = 'raw/from_lit_for_m2_enrichment_a.xlsx'\n",
    "import pandas as pd\n",
    "df_orig = pd.read_excel(io.BytesIO(load_from_s3(file).read())).dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "formulas = df_orig['Composition'].values.tolist()\n",
    "\n",
    "print('Total entries:', len(formulas))\n",
    "\n",
    "\n",
    "from pymatgen.ext.matproj import MPRestError\n",
    "mpids = []\n",
    "mpids_formulas = []\n",
    "for i in range (0,len(formulas)):\n",
    "    try:\n",
    "        mpids.append(mpr.get_materials_ids(formulas[i]))\n",
    "    except MPRestError:\n",
    "        print('Remove this formula:', formulas[i])\n",
    "    else:\n",
    "         mpids_formulas.append(mpr.query(mpids[i][0], [\"pretty_formula\"]))\n",
    "                \n",
    "a = []\n",
    "for i in range(0, len(mpids_formulas)):\n",
    "    a.append(mpids_formulas[i][0]['pretty_formula'])\n",
    "mpids_formulas = a\n",
    "\n",
    "df_orig['Formula'] = mpids_formulas\n",
    "\n",
    "mpids_concat = []\n",
    "for j in mpids:\n",
    "    for i in range (0,len(j)):\n",
    "        mpids_concat.append(j[i])\n",
    "print(mpids_concat)\n",
    "\n",
    "data = []\n",
    "for i in range(0,len(mpids_concat)):\n",
    "    data.append(mpr.query(mpids_concat[i], ['material_id', \"pretty_formula\", \"spacegroup.number\", \"band_gap\"])) \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data = [])\n",
    "df['mpids'] = [p[0]['material_id'] for p in data]\n",
    "df['Formula'] = [p[0]['pretty_formula'] for p in data]\n",
    "df['SG'] = [p[0]['spacegroup.number'] for p in data]\n",
    "df['BG_MP'] = [p[0]['band_gap'] for p in data]\n",
    "\n",
    "rslt_df_1 = pd.DataFrame(data=[])\n",
    "rslt_df_2 = pd.DataFrame(data=[])\n",
    "for i in range(0,len(df_orig)):\n",
    "    rslt_df_1 = df[(df['Formula'] == df_orig.loc[i]['Formula']) & \n",
    "                 (df['SG'] == df_orig.loc[i]['G'])\n",
    "                 ]\n",
    "    rslt_df_1['Eg(Exp)'] =  df_orig.loc[i]['Eg(Exp)']\n",
    "    if len(rslt_df_1) > 1:\n",
    "        print(\"Multiple entries\", rslt_df_1)\n",
    "        rslt_df_1 = rslt_df_1.iloc[0]\n",
    "        print(\"First one is selected\")\n",
    "    rslt_df_2 = rslt_df_2.append(rslt_df_1)\n",
    "    \n",
    "rslt_df_2.to_excel('Datasets/processed_step1/Dataset_for_enrichment_aX.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE LOADED\n"
     ]
    }
   ],
   "source": [
    "#For enrich_b, we are applying minimal changes at this step. Will process this heavily later.\n",
    "\n",
    "file = 'raw/from_lit_for_m2_enrichment_b.xlsx'\n",
    "enrich_b = pd.read_excel(io.BytesIO(load_from_s3(file).read())).reset_index(drop=True)\n",
    "\n",
    "# Drop mp-557056, mp-24850, mp-25054, mp-25176, mp-542885\n",
    "enrich_b = enrich_b.drop(enrich_b.index[enrich_b['mpids'] == 'mp-557056']).reset_index(drop=True)\n",
    "enrich_b = enrich_b.drop(enrich_b.index[enrich_b['mpids'] == 'mp-24850']).reset_index(drop=True)\n",
    "enrich_b = enrich_b.drop(enrich_b.index[enrich_b['mpids'] == 'mp-25054']).reset_index(drop=True)\n",
    "enrich_b = enrich_b.drop(enrich_b.index[enrich_b['mpids'] == 'mp-25176']).reset_index(drop=True)\n",
    "enrich_b = enrich_b.drop(enrich_b.index[enrich_b['mpids'] == 'mp-542885']).reset_index(drop=True)\n",
    "\n",
    "text = enrich_b.columns[-1]\n",
    "enrich_b = enrich_b.rename(columns = {text: 'ref'})\n",
    "text = '10.1007/978-3-642-18865-7, Semiconductors: Data Handbook, Otfried Madelung, Springer-Verlag Berlin Heidelberg, 2004'\n",
    "for i in range (len(enrich_b)):\n",
    "    if pd.isnull(enrich_b.loc[i,'ref']):\n",
    "        enrich_b.at[i,'ref'] = text\n",
    "\n",
    "enrich_b.to_excel('Datasets/processed_step1/Dataset_for_enrichment_bX.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESSING STEP - 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this step is as follows:\n",
    "- Wrangling datasets based on band gap cut-off of 5 eV\n",
    "- Removing validation samples from datasets used for developing M1 and M2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_cutoff = 5\n",
    "\n",
    "file_1 = 'Datasets/processed_step1/Dataset_DS1_fromraw.xlsx'\n",
    "file_2 = 'Datasets/processed_step1/Dataset_DS2_fromraw.xlsx'\n",
    "file_3 = 'Datasets/processed_step1/Dataset_for_validation.xlsx'\n",
    "file_4 = 'Datasets/processed_step1/Dataset_for_enrichment_a.xlsx'\n",
    "file_5 = 'Datasets/processed_step1/Dataset_for_enrichment_b.xlsx'\n",
    "\n",
    "\n",
    "m1 = pd.ExcelFile(file_1).parse('Sheet1').rename(str.lower, axis='columns')\n",
    "m2 = pd.ExcelFile(file_2).parse('Sheet1').rename(str.lower, axis='columns')\n",
    "validation = pd.ExcelFile(file_3).parse('Sheet1').rename(str.lower, axis='columns')\n",
    "enrich_a = pd.ExcelFile(file_4).parse('Sheet1').rename(str.lower, axis='columns')\n",
    "enrich_b = pd.ExcelFile(file_5).parse('Sheet1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing M1\n",
    "processed_m1 = m1[(m1['bg_mp'] < bg_cutoff) ].drop('unnamed: 0', 1).reset_index(drop=True)\n",
    "\n",
    "# Processing validation\n",
    "processed_validation = validation.rename(columns={'exp.':'bg_exp',\n",
    "                                                  'hse':'bg_hse',\n",
    "                                                  'g0w0':'bg_gw'\n",
    "                                                  }).drop('unnamed: 0', 1).reset_index(drop=True)\n",
    "\n",
    "# Removing val from M1\n",
    "overlap_m1_val = processed_m1[processed_m1.mpids.isin(processed_validation.mpids)]\n",
    "processed_m1_noval = processed_m1[~processed_m1.mpids.isin(processed_validation.mpids)]\n",
    "\n",
    "# Processing M2\n",
    "m2.drop('formula_exp', 1, inplace = True)\n",
    "\n",
    "for i in range(0,len(m2)):\n",
    "    if type(m2.iloc[i]['bg_exp']) is str:\n",
    "        print ('index:',i,'\\n',m2.iloc[i], '\\n')\n",
    "m2.at[98, 'bg_exp'] , m2.at[99, 'bg_exp'] = 3.8 , 3.7\n",
    "m2['bg_exp'] = pd.to_numeric(m2['bg_exp'],errors = 'coerce')\n",
    "\n",
    "m2_norep = m2.drop_duplicates(subset=['mpids'], keep='first')\n",
    "\n",
    "processed_m2 = m2_norep.drop('unnamed: 0', 1).reset_index(drop=True)\n",
    "\n",
    "overlap_m2_val = processed_m2[processed_m2.mpids.isin(processed_validation.mpids)]\n",
    "processed_m2_noval = processed_m2[~processed_m2.mpids.isin(processed_validation.mpids)].reset_index(drop=True)\n",
    "\n",
    "processed_m2 = processed_m2[(processed_m2['bg_exp'] < bg_cutoff) ].reset_index(drop=True)\n",
    "processed_m2_noval = processed_m2_noval[(processed_m2_noval['bg_exp'] < bg_cutoff) ].reset_index(drop=True)\n",
    "\n",
    "# Processing enrichment dataset & Concat with M2\n",
    "enrich_a.rename(columns={'eg(exp)':'bg_exp'}, inplace = True)\n",
    "\n",
    "m2_enrich_a = pd.concat([m2_norep, enrich_a], axis = 0)\n",
    "m2_enrich_a.drop_duplicates(subset=['mpids'], keep='first', inplace = True)\n",
    "\n",
    "processed_m2_enrich_a = m2_enrich_a.drop('unnamed: 0', 1).reset_index(drop=True)\n",
    "\n",
    "overlap_m2_enrich_a_val = processed_m2_enrich_a[processed_m2_enrich_a.mpids.isin(processed_validation.mpids)]\n",
    "processed_m2_enrich_a_noval = processed_m2_enrich_a[~processed_m2_enrich_a.mpids.isin(processed_validation.mpids)].reset_index(drop=True)\n",
    "\n",
    "processed_m2_enrich_a = processed_m2_enrich_a[(processed_m2_enrich_a['bg_exp'] < bg_cutoff) ].reset_index(drop=True)\n",
    "processed_m2_enrich_a_noval = processed_m2_enrich_a_noval[(processed_m2_enrich_a_noval['bg_exp'] < bg_cutoff) ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save files\n",
    "processed_m1_noval.to_excel('Datasets/processed_step2/processed_ds1.xlsx')\n",
    "processed_m2_enrich_a_noval.to_excel('Datasets/processed_step2/processed_ds2_a.xlsx')\n",
    "processed_validation.to_excel('Datasets/processed_step2/processed_ds3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of bandgaps in validation set\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.displot(processed_validation, x=\"bg_mp\", kde=True)\n",
    "ax.set(xlabel='DFT(PBE) bandgaps', ylabel='Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing enrichment set b for DS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.io.cif import CifParser\n",
    "MAPI_KEY = MAPI_KEY\n",
    "mpr = MPRester(MAPI_KEY)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "enrich_b = enrich_b.drop('Unnamed: 0', 1).reset_index(drop=True)\n",
    "\n",
    "#Drop duplicates\n",
    "# Remove ds2_a from enrich_b\n",
    "enrich_b = enrich_b[~enrich_b.mpids.isin(processed_m2_enrich_a_noval.mpids)].reset_index(drop=True)\n",
    "\n",
    "# Remove validation from enrich_b\n",
    "enrich_b = enrich_b[~enrich_b.mpids.isin(processed_validation.mpids)].reset_index(drop=True)\n",
    "\n",
    "# Check overlap\n",
    "print(enrich_b[enrich_b.mpids.isin(processed_m2_enrich_a_noval.mpids)])\n",
    "print(enrich_b[enrich_b.mpids.isin(processed_validation.mpids)])\n",
    "print(enrich_b[enrich_b.mpids.isin(processed_m1_noval.mpids)]) #Overlap with DS1 does not matter since all of these are going to DS2 for training. The print for above two must return an empty list.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get bandgaps from Materials Project\n",
    "\n",
    "QUERY = enrich_b['mpids'].values.tolist()\n",
    "\n",
    "prop_bg = []\n",
    "from pymatgen.ext.matproj import MPRestError\n",
    "for i in range(0,len(QUERY)):\n",
    "    try:\n",
    "        prop_bg.append(mpr.query(QUERY[i], ['band_gap']))\n",
    "    except MPRestError:\n",
    "        print('MPRestError for:',QUERY[i])\n",
    "    else:\n",
    "       pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to check if there are any empty entries\n",
    "for i in range(0,len(prop_bg)):\n",
    "    if prop_bg[i] == []:\n",
    "        print(str(i) + ' is empty')\n",
    "        #prop_bg.remove(prop_bg[i])\n",
    "        #print(str(prop_bg[i]) + ' is deleted')\n",
    "       \n",
    "# If there are some [] entries in prop_bg then running code below will give out of range error\n",
    "enrich_b['bg_mp'] = [p[0]['band_gap'] for p in prop_bg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check structure and get cifs\n",
    "# structures_cif = []\n",
    "# for i in range(0,len(QUERY)):\n",
    "#     structures_cif.append(mpr.get_data(QUERY[i], data_type = '', prop = 'cif').get('cif'))\n",
    "# print(\"No. of structures:\",len(structures_cif))\n",
    "\n",
    "# #Save structures in cif file\n",
    "# for i in range(0,len(structures_cif)):\n",
    "#     with open('cif/{}.cif'.format(QUERY[i]),'w') as output:\n",
    "#         output.write(structures_cif[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove items outside bg threshold\n",
    "bg_cutoff = 5\n",
    "enrich_b = enrich_b[ (enrich_b['bg_exp'] <= bg_cutoff)].reset_index(drop=True)\n",
    "\n",
    "#Rearrange columns\n",
    "cols = enrich_b.columns.tolist()\n",
    "cols_new = cols[:-2] + cols[-1:] + cols[-2:-1]\n",
    "enrich_b = enrich_b[cols_new]\n",
    "\n",
    "enrich_b.to_excel('Datasets/processed_step2/processed_ds2_b.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL PROCESSING STEP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating DS2 subsets and saving all finalized datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24727/178158609.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_ds1 = df_ds1.drop('unnamed: 0',1)\n",
      "/tmp/ipykernel_24727/178158609.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_ds3 = df_ds3.drop('unnamed: 0',1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE SAVED\n",
      "FILE SAVED\n",
      "FILE SAVED\n"
     ]
    }
   ],
   "source": [
    "df_ds1 = pd.ExcelFile('Datasets/processed_step2/processed_ds1.xlsx').parse('Sheet1').rename(str.lower, axis='columns')\n",
    "df_ds2_a = pd.ExcelFile('Datasets/processed_step2/processed_ds2_a.xlsx').parse('Sheet1').rename(str.lower, axis='columns')\n",
    "df_ds2_b = pd.ExcelFile('Datasets/processed_step2/processed_ds2_b.xlsx').parse('Sheet1').rename(str.lower, axis='columns')\n",
    "df_ds3 = pd.ExcelFile('Datasets/processed_step2/processed_ds3.xlsx').parse('Sheet1').rename(str.lower, axis='columns')\n",
    "\n",
    "df_ds2 = pd.concat( [ df_ds2_a[['mpids','formula','bg_mp','bg_exp']] , df_ds2_b[['mpids','formula','bg_mp','bg_exp']]  ] , axis = 0 ).reset_index(drop=True)\n",
    "\n",
    "df_ds1 = df_ds1.drop('unnamed: 0',1)\n",
    "df_ds3 = df_ds3.drop('unnamed: 0',1)\n",
    "\n",
    "#Saving finalized spread sheets to AWS S3 bucket\n",
    "save_to_s3(df_ds1, 'processed/processed_ds1.xlsx')\n",
    "save_to_s3(df_ds2, 'processed/processed_ds2.xlsx')\n",
    "save_to_s3(df_ds3, 'processed/processed_ds3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving JSON\n",
    "df_ds1 = df_ds1.set_index('mpids')\n",
    "df_ds1_json = df_ds1.to_json(orient=\"index\")\n",
    "df_ds1_json = json.loads(df_ds1_json)\n",
    "\n",
    "df_ds2 = df_ds2.set_index('mpids')\n",
    "df_ds2_json = df_ds2.to_json(orient=\"index\")\n",
    "df_ds2_json = json.loads(df_ds2_json)\n",
    "\n",
    "df_ds3 = df_ds3.set_index('mpids')\n",
    "df_ds3_json = df_ds3.to_json(orient=\"index\")\n",
    "df_ds3 = json.loads(df_ds3_json)\n",
    "\n",
    "with open('Datasets/json/ds1_json.json', 'w') as f:\n",
    "    json.dump(df_ds1_json, f,indent=2)\n",
    "    \n",
    "with open('Datasets/json/ds2_json.json', 'w') as f:\n",
    "    json.dump(df_ds2_json, f,indent=2) \n",
    "    \n",
    "with open('Datasets/json/ds3_json.json', 'w') as f:\n",
    "    json.dump(df_ds3_json, f,indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgcnn_matai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17176484f3abb3507b67289d4e44e03b92f0647a7774abb1b3f41626c1f89f23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
